{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.py",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayaabdo/Image-Paragraph-Captioning/blob/master/IPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npblJ8E8GoJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# You'll generate plots of attention in order to see which parts of an image\n",
        "# our model focuses on during captioning\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scikit-learn includes many helpful utilities\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fFdzkmc92Xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download caption annotation files\n",
        "annotation_folder = '/annotations/'\n",
        "if not os.path.exists(os.path.abspath('.') + annotation_folder):\n",
        "  annotation_zip = tf.keras.utils.get_file('captions.zip',\n",
        "                                          cache_subdir=os.path.abspath('.'),\n",
        "                                          origin = 'http://images.cocodataset.org/annotations/annotations_trainval2014.zip',\n",
        "                                          extract = True)\n",
        "  annotation_file = os.path.dirname(annotation_zip)+'/annotations/captions_train2014.json'\n",
        "  os.remove(annotation_zip)\n",
        "\n",
        "# Download image files\n",
        "image_folder = '/train2014/'\n",
        "if not os.path.exists(os.path.abspath('.') + image_folder):\n",
        "  image_zip = tf.keras.utils.get_file('train2014.zip',\n",
        "                                      cache_subdir=os.path.abspath('.'),\n",
        "                                      origin = 'http://images.cocodataset.org/zips/train2014.zip',\n",
        "                                      extract = True)\n",
        "  PATH = os.path.dirname(image_zip) + image_folder\n",
        "  os.remove(image_zip)\n",
        "else:\n",
        "  PATH = os.path.abspath('.') + image_folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN3ZDT4DWvAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#!/usr/bin/env python\n",
        "# coding=utf-8\n",
        "\n",
        "# __author__ = \"Xinpeng.Chen\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "import pdb\n",
        "\n",
        "tf.compat.v1.disable_v2_behavior()\n",
        "# keep plt running backend mode\n",
        "# https://stackoverflow.com/questions/4931376/generating-matplotlib-graphs-without-a-running-x-server \n",
        "import matplotlib as mpl\n",
        "mpl.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# set up GPU usage   \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "# upgrade to tensorflow 1.4\n",
        "if tf.__version__ < '1.2':\n",
        "    print (\"tensorflow version is too old\")\n",
        "\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "# Initialization class\n",
        "#  1. Pooling the visual features into a single dense feature\n",
        "#  2. Then, build sentence LSTM, word LSTM\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "class RegionPooling_HierarchicalRNN():\n",
        "    def __init__(self, n_words,\n",
        "                       batch_size,\n",
        "                       num_boxes,\n",
        "                       feats_dim,\n",
        "                       project_dim,\n",
        "                       sentRNN_lstm_dim,\n",
        "                       sentRNN_FC_dim,\n",
        "                       wordRNN_lstm_dim,\n",
        "                       S_max,\n",
        "                       N_max,\n",
        "                       word_embed_dim,\n",
        "                       bias_init_vector=None):\n",
        "\n",
        "        self.n_words = n_words\n",
        "        self.batch_size = batch_size\n",
        "        self.num_boxes = num_boxes # 50\n",
        "        self.feats_dim = feats_dim # 4096\n",
        "        self.project_dim = project_dim # 1024\n",
        "        self.S_max = S_max # 6\n",
        "        self.N_max = N_max # 50\n",
        "        self.word_embed_dim = word_embed_dim # 1024\n",
        "\n",
        "        self.sentRNN_lstm_dim = sentRNN_lstm_dim # 512 hidden size\n",
        "        self.sentRNN_FC_dim = sentRNN_FC_dim # 1024 in fully connected layer\n",
        "        self.wordRNN_lstm_dim = wordRNN_lstm_dim # 512 hidden size\n",
        "\n",
        "        # word embedding, parameters of embedding\n",
        "        # embedding shape: n_words x wordRNN_lstm_dim\n",
        "        #with tf.device('/cpu:0'):\n",
        "        self.Wemb = tf.Variable(tf.random.uniform([n_words, word_embed_dim], -0.1, 0.1), name='Wemb')\n",
        "        #self.bemb = tf.Variable(tf.zeros([word_embed_dim]), name='bemb')\n",
        "        # regionPooling_W shape: 4096 x 1024\n",
        "        # regionPooling_b shape: 1024\n",
        "        self.regionPooling_W = tf.Variable(tf.random.uniform([feats_dim, project_dim], -0.1, 0.1), name='regionPooling_W')\n",
        "        self.regionPooling_b = tf.Variable(tf.zeros([project_dim]), name='regionPooling_b')\n",
        "        # sentence LSTM\n",
        "        #self.sent_LSTM = tf.keras.layers.LSTM(sentRNN_lstm_dim, state_is_tuple=True)\n",
        "        #self.sent_LSTM = tf.contrib.cudnn_rnn.CudnnLSTM(sentRNN_lstm_dim, state_is_tuple=True)\n",
        "        self.sent_LSTM = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(sentRNN_lstm_dim, state_is_tuple=True)\n",
        "        # logistic classifier\n",
        "        self.logistic_Theta_W = tf.Variable(tf.random.uniform([sentRNN_lstm_dim, 2], -0.1, 0.1), name='logistic_Theta_W')\n",
        "        self.logistic_Theta_b = tf.Variable(tf.zeros(2), name='logistic_Theta_b')\n",
        "\n",
        "        # fc1_W: 512 x 1024, fc1_b: 1024\n",
        "        # fc2_W: 1024 x 1024, fc2_b: 1024\n",
        "        self.fc1_W = tf.Variable(tf.random.uniform([sentRNN_lstm_dim, sentRNN_FC_dim], -0.1, 0.1), name='fc1_W')\n",
        "        self.fc1_b = tf.Variable(tf.zeros(sentRNN_FC_dim), name='fc1_b')\n",
        "        self.fc2_W = tf.Variable(tf.random.uniform([sentRNN_FC_dim, 1024], -0.1, 0.1), name='fc2_W')\n",
        "        self.fc2_b = tf.Variable(tf.zeros(1024), name='fc2_b')\n",
        "\n",
        "        # word LSTM\n",
        "        # https://github.com/tensorflow/tensorflow/issues/16186\n",
        "        \n",
        "        def wordLSTM():\n",
        "            #lstm = tf.contrib.cudnn_rnn.CudnnLSTM(wordRNN_lstm_dim, state_is_tuple=True)\n",
        "            lstm = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(wordRNN_lstm_dim, state_is_tuple=True)\n",
        "            #print(\"wordLstm\")\n",
        "            return lstm\n",
        "        self.word_LSTM = tf.compat.v1.nn.rnn_cell.MultiRNNCell([wordLSTM() for _ in range(2)], state_is_tuple=True)\n",
        "        #self.word_LSTM = tf.compat.v1.nn.rnn_cell.MultiRNNCell([wordLSTM() for _ in range(2)], state_is_tuple=True)\n",
        "        #print('eshta ya sa7by')\n",
        "        # self.word_LSTM = tf.nn.rnn_cell.BasicLSTMCell(wordRNN_lstm_dim, state_is_tuple=True)   --cxp\n",
        "        # self.word_LSTM = tf.nn.rnn_cell.MultiRNNCell([self.word_LSTM] * 2, state_is_tuple=True)   --cxp\n",
        "        # self.word_LSTM2 = tf.nn.rnn_cell.BasicLSTMCell(wordRNN_lstm_dim, state_is_tuple=True)\n",
        "\n",
        "        self.embed_word_W = tf.Variable(tf.random.uniform([wordRNN_lstm_dim, n_words], -0.1,0.1), name='embed_word_W')\n",
        "        \n",
        "        tf.compat.v1.get_variable_scope().reuse_variables()\n",
        "        if bias_init_vector is not None:\n",
        "            self.embed_word_b = tf.Variable(bias_init_vector.astype(np.float32), name='embed_word_b')\n",
        "        else:\n",
        "            self.embed_word_b = tf.Variable(tf.zeros([n_words]), name='embed_word_b')\n",
        "\n",
        "    def build_model(self):\n",
        "        # receive the feats in the current image\n",
        "        # it's shape is 1 x C x 2048\n",
        "        # tmp_feats: C x 2048\n",
        "        #tf.compat.v1.disable_eager_execution()\n",
        "        feats = tf.compat.v1.placeholder(tf.float32, [self.batch_size, self.num_boxes, self.feats_dim])\n",
        "        tmp_feats = tf.reshape(feats, [-1, self.feats_dim])\n",
        "        print(feats.shape)\n",
        "        # project_vec_all: C x 2048 * 2048 x 1024 --> C x 1024\n",
        "        # project_vec: 1 x 1024\n",
        "        project_vec_all = tf.matmul(tmp_feats, self.regionPooling_W) + self.regionPooling_b\n",
        "        project_vec_all = tf.reshape(project_vec_all, [self.batch_size, 50, self.project_dim])\n",
        "        project_vec = tf.math.reduce_max(input_tensor=project_vec_all, axis=1)\n",
        "        #print('zft',project_vec.shape)\n",
        "\n",
        "        # receive the [continue:0, stop:1] lists\n",
        "        # example: [0, 0, 0, 0, 1, 1], it means this paragraph has five sentences\n",
        "        num_distribution = tf.compat.v1.placeholder(tf.int32, [self.batch_size, self.S_max])\n",
        "\n",
        "        # receive the ground truth words, which has been changed to idx use word2idx function\n",
        "        captions = tf.compat.v1.placeholder(tf.int32, [self.batch_size, self.S_max, self.N_max+1])\n",
        "        captions_masks = tf.compat.v1.placeholder(tf.float32, [self.batch_size, self.S_max, self.N_max+1])\n",
        "\n",
        "        # ---------------------------------------------------------------------------------------------------------------------\n",
        "        # The method which initialize the state, is refered from below sites:\n",
        "        # 1. http://stackoverflow.com/questions/38241410/tensorflow-remember-lstm-state-for-next-batch-stateful-lstm/38417699\n",
        "        # 2. https://www.tensorflow.org/api_docs/python/rnn_cell/classes_storing_split_rnncell_state#LSTMStateTuple\n",
        "        # 3. https://medium.com/@erikhallstrm/using-the-tensorflow-lstm-api-3-7-5f2b97ca6b73#.u4w9z6h0h\n",
        "        # ---------------------------------------------------------------------------------------------------------------------\n",
        "        sent_state = self.sent_LSTM.zero_state(batch_size=self.batch_size, dtype=tf.float32)\n",
        "        #word_state = self.word_LSTM.zero_state(batch_size=self.batch_size, dtype=tf.float32)\n",
        "        #word_state1 = self.word_LSTM1.zero_state(batch_size=self.batch_size, dtype=tf.float32)\n",
        "        #word_state2 = self.word_LSTM2.zero_state(batch_size=self.batch_size, dtype=tf.float32)\n",
        "        #sent_state = tf.zeros([self.batch_size, self.sent_LSTM1.state_size])\n",
        "        #word_state1 = tf.zeros([self.batch_size, self.word_LSTM1.state_size])\n",
        "        #word_state2 = tf.zeros([self.batch_size, self.word_LSTM2.state_size])\n",
        "\n",
        "        probs = []\n",
        "        loss = 0.0\n",
        "        loss_sent = 0.0\n",
        "        loss_word = 0.0\n",
        "        lambda_sent = 5.0\n",
        "        lambda_word = 1.0\n",
        "\n",
        "        print ('Start build model:')\n",
        "        #----------------------------------------------------------------------------------------------\n",
        "        # Hierarchical RNN: sentence RNN and words RNN\n",
        "        # The word RNN has the max number, N_max = 50, the number in the papar is 50\n",
        "        #----------------------------------------------------------------------------------------------\n",
        "        for i in range(0, self.S_max):\n",
        "            \n",
        "            if i > 0:\n",
        "                tf.compat.v1.get_variable_scope().reuse_variables()\n",
        "\n",
        "            # https://www.tensorflow.org/api_docs/python/tf/variable_scope\n",
        "            with tf.compat.v1.variable_scope('sent_LSTM', reuse=tf.compat.v1.AUTO_REUSE):\n",
        "                sent_output, sent_state = self.sent_LSTM(project_vec, sent_state)\n",
        "\n",
        "            with tf.compat.v1.name_scope('fc1'):\n",
        "                hidden1 = tf.nn.relu( tf.matmul(sent_output, self.fc1_W) + self.fc1_b )\n",
        "            with tf.compat.v1.name_scope('fc2'):\n",
        "                sent_topic_vec = tf.nn.relu( tf.matmul(hidden1, self.fc2_W) + self.fc2_b )\n",
        "            #print('relu')\n",
        "\n",
        "            # sent_state is a tuple, sent_state = (c, h)\n",
        "            # 'c': shape=(1, 512) dtype=float32, 'h': shape=(1, 512) dtype=float32\n",
        "            # The loss here, I refer from the web which is very helpful for me:\n",
        "            # 1. http://stackoverflow.com/questions/34240703/difference-between-tensorflow-tf-nn-softmax-and-tf-nn-softmax-cross-entropy-with\n",
        "            # 2. http://stackoverflow.com/questions/35277898/tensorflow-for-binary-classification\n",
        "            # 3. http://stackoverflow.com/questions/35226198/is-this-one-hot-encoding-in-tensorflow-fast-or-flawed-for-any-reason\n",
        "            # 4. http://stackoverflow.com/questions/35198528/reshape-y-train-for-binary-text-classification-in-tensorflow\n",
        "            sentRNN_logistic_mu = tf.compat.v1.nn.xw_plus_b( sent_output, self.logistic_Theta_W, self.logistic_Theta_b )\n",
        "            sentRNN_label = tf.stack([ 1 - num_distribution[:, i], num_distribution[:, i] ])\n",
        "            sentRNN_label = tf.transpose(a=sentRNN_label)\n",
        "            # https://github.com/ibab/tensorflow-wavenet/issues/223\n",
        "            sentRNN_loss = tf.nn.softmax_cross_entropy_with_logits(labels=tf.stop_gradient(sentRNN_label), logits=sentRNN_logistic_mu)\n",
        "            sentRNN_loss = tf.reduce_sum(input_tensor=sentRNN_loss)/self.batch_size\n",
        "            loss += sentRNN_loss * lambda_sent\n",
        "            loss_sent += sentRNN_loss\n",
        "\n",
        "            # the begining input of word_LSTM is topic vector, and DON'T compute the loss\n",
        "            # This is follow the paper: Show and Tell\n",
        "            #word_state = self.word_LSTM.zero_state(batch_size=self.batch_size, dtype=tf.float32)\n",
        "            #with tf.variable_scope('word_LSTM'):\n",
        "            #    word_output, word_state = self.word_LSTM(sent_topic_vec)\n",
        "\n",
        "            topic = tf.compat.v1.nn.rnn_cell.LSTMStateTuple(sent_topic_vec[:, 0:512], sent_topic_vec[:, 512:])\n",
        "            word_state = (topic, topic)\n",
        "\n",
        "            # tf.reset_default_graph()\n",
        "            for j in range(0, self.N_max):\n",
        "                if j > 0:\n",
        "                  tf.compat.v1.get_variable_scope().reuse_variables()\n",
        "\n",
        "                with tf.device('/cpu:0'):\n",
        "                  current_embed = tf.compat.v1.nn.embedding_lookup(self.Wemb, captions[:, i, j])\n",
        "                with tf.compat.v1.variable_scope('word_LSTM', reuse=tf.compat.v1.AUTO_REUSE):\n",
        "                    # pdb.set_trace()\n",
        "                    word_output, word_state = self.word_LSTM(current_embed, word_state)\n",
        "\n",
        "                # How to make one-hot encoder\n",
        "                # http://stackoverflow.com/questions/33681517/tensorflow-one-hot-encoder\n",
        "                labels = tf.reshape(captions[:, i, j+1], [-1, 1])\n",
        "                indices = tf.reshape(tf.range(0, self.batch_size, 1), [-1, 1])\n",
        "                # https://www.tensorflow.org/api_docs/python/tf/concat\n",
        "                concated = tf.concat([indices, labels], 1)\n",
        "                onehot_labels = tf.compat.v1.sparse_to_dense(concated, tf.stack([self.batch_size, self.n_words]), 1.0, 0.0)\n",
        "\n",
        "                # At each timestep the hidden state of the last LSTM layer is used to predict a distribution\n",
        "                # over the words in the vocbulary\n",
        "                logit_words = tf.compat.v1.nn.xw_plus_b(word_output[:], self.embed_word_W, self.embed_word_b)\n",
        "                cross_entropy = tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=logit_words, labels=onehot_labels)\n",
        "                cross_entropy = cross_entropy * captions_masks[:, i, j]\n",
        "                loss_wordRNN = tf.compat.v1.reduce_sum(cross_entropy) / self.batch_size\n",
        "                loss += loss_wordRNN * lambda_word\n",
        "                loss_word += loss_wordRNN\n",
        "\n",
        "        return feats, num_distribution, captions, captions_masks, loss, loss_sent, loss_word\n",
        "\n",
        "    def generate_model(self):\n",
        "        # feats: 1 x 50 x 4096\n",
        "        feats = tf.compat.v1.placeholder(tf.float32, [1, self.num_boxes, self.feats_dim])\n",
        "        # tmp_feats: 50 x 4096\n",
        "        tmp_feats = tf.reshape(feats, [-1, self.feats_dim])\n",
        "\n",
        "        # project_vec_all: 50 x 4096 * 4096 x 1024 + 1024 --> 50 x 1024\n",
        "        project_vec_all = tf.matmul(tmp_feats, self.regionPooling_W) + self.regionPooling_b\n",
        "        project_vec_all = tf.reshape(project_vec_all, [1, 50, self.project_dim])\n",
        "        project_vec = tf.reduce_max(input_tensor=project_vec_all, axis=1)\n",
        "\n",
        "        # initialize the sent_LSTM state\n",
        "        sent_state = self.sent_LSTM.zero_state(batch_size=1, dtype=tf.float32)\n",
        "\n",
        "        # save the generated paragraph to list, here I named generated_sents\n",
        "        generated_paragraph = []\n",
        "\n",
        "        # pred\n",
        "        pred_re = []\n",
        "\n",
        "        # T_stop: run the sentence RNN forward until the stopping probability p_i (STOP) exceeds a threshold T_stop\n",
        "        T_stop = tf.constant(0.5)\n",
        "\n",
        "        # Start build the generation model\n",
        "        print ('Start build the generation model: ')\n",
        "\n",
        "        # sentence RNN\n",
        "        #word_state = self.word_LSTM.zero_state(batch_size=1, dtype=tf.float32)\n",
        "        #with tf.variable_scope('word_LSTM'):\n",
        "        #    word_output, word_state = self.word_LSTM(sent_topic_vec, word_state)\n",
        "        for i in range(0, self.S_max):\n",
        "            if i > 0:\n",
        "                tf.compat.v1.get_variable_scope().reuse_variables()\n",
        "\n",
        "            # sent_state:\n",
        "            # LSTMStateTuple(c=<tf.Tensor 'sent_LSTM/BasicLSTMCell/add_2:0' shape=(1, 512) dtype=float32>,\n",
        "            #                h=<tf.Tensor 'sent_LSTM/BasicLSTMCell/mul_2:0' shape=(1, 512) dtype=float32>)\n",
        "            with tf.compat.v1.variable_scope('sent_LSTM', reuse=tf.compat.v1.AUTO_REUSE):\n",
        "                sent_output, sent_state = self.sent_LSTM(project_vec, sent_state)\n",
        "\n",
        "            # self.fc1_W: 512 x 1024, self.fc1_b: 1024\n",
        "            # hidden1: 1 x 1024\n",
        "            # sent_topic_vec: 1 x 1024\n",
        "            with tf.compat.v1.name_scope('fc1'):\n",
        "                hidden1 = tf.nn.relu( tf.matmul(sent_output, self.fc1_W) + self.fc1_b )\n",
        "            with tf.compat.v1.name_scope('fc2'):\n",
        "                sent_topic_vec = tf.nn.relu( tf.matmul(hidden1, self.fc2_W) + self.fc2_b )\n",
        "\n",
        "            sentRNN_logistic_mu = tf.compat.v1.nn.xw_plus_b(sent_output, self.logistic_Theta_W, self.logistic_Theta_b)\n",
        "            pred = tf.nn.softmax(sentRNN_logistic_mu)\n",
        "            pred_re.append(pred)\n",
        "\n",
        "            # save the generated sentence to list, named generated_sent\n",
        "            generated_sent = []\n",
        "\n",
        "            # initialize the word LSTM state\n",
        "            #word_state = self.word_LSTM.zero_state(batch_size=1, dtype=tf.float32)\n",
        "            #with tf.variable_scope('word_LSTM'):\n",
        "            #    word_output, word_state = self.word_LSTM(sent_topic_vec, word_state)\n",
        "            topic = tf.compat.v1.nn.rnn_cell.LSTMStateTuple(sent_topic_vec[:, 0:512], sent_topic_vec[:, 512:])\n",
        "            word_state = (topic, topic)\n",
        "            # word RNN, unrolled to N_max time steps\n",
        "            for j in range(0, self.N_max):\n",
        "                if j > 0:\n",
        "                    tf.compat.v1.get_variable_scope().reuse_variables()\n",
        "\n",
        "                if j == 0:\n",
        "                    with tf.device('/cpu:0'):\n",
        "                        # get word embedding of BOS (index = 0)\n",
        "                        current_embed = tf.nn.embedding_lookup(params=self.Wemb, ids=tf.zeros([1], dtype=tf.int64))\n",
        "\n",
        "                with tf.compat.v1.variable_scope('word_LSTM', reuse=tf.compat.v1.AUTO_REUSE):\n",
        "                    word_output, word_state = self.word_LSTM(current_embed, word_state)\n",
        "\n",
        "                # word_state:\n",
        "                # (\n",
        "                #     LSTMStateTuple(c=<tf.Tensor 'word_LSTM_152/MultiRNNCell/Cell0/BasicLSTMCell/add_2:0' shape=(1, 512) dtype=float32>,\n",
        "                #                    h=<tf.Tensor 'word_LSTM_152/MultiRNNCell/Cell0/BasicLSTMCell/mul_2:0' shape=(1, 512) dtype=float32>),\n",
        "                #     LSTMStateTuple(c=<tf.Tensor 'word_LSTM_152/MultiRNNCell/Cell1/BasicLSTMCell/add_2:0' shape=(1, 512) dtype=float32>,\n",
        "                #                    h=<tf.Tensor 'word_LSTM_152/MultiRNNCell/Cell1/BasicLSTMCell/mul_2:0' shape=(1, 512) dtype=float32>)\n",
        "                # )\n",
        "                logit_words = tf.compat.v1.nn.xw_plus_b(word_output, self.embed_word_W, self.embed_word_b)\n",
        "                max_prob_index = tf.argmax(input=logit_words, axis=1)[0]\n",
        "                generated_sent.append(max_prob_index)\n",
        "\n",
        "                with tf.device('/cpu:0'):\n",
        "                    current_embed = tf.nn.embedding_lookup(params=self.Wemb, ids=max_prob_index)\n",
        "                    current_embed = tf.expand_dims(current_embed, 0)\n",
        "\n",
        "            generated_paragraph.append(generated_sent)\n",
        "\n",
        "        # return feats, generated_paragraph, pred_re, --cxp\n",
        "        return feats, generated_paragraph, pred_re, generated_sent\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------------------------------\n",
        "# Preparing Functions\n",
        "# -----------------------------------------------------------------------------------------------------\n",
        "def preProBuildWordVocab(sentence_iterator, word_count_threshold=5):\n",
        "    # borrowed this function from NeuralTalk\n",
        "    print ('preprocessing word counts and creating vocab based on word count threshold %d' % (word_count_threshold, ))\n",
        "\n",
        "    word_counts = {}\n",
        "    nsents = 0\n",
        "\n",
        "    for sent in sentence_iterator:\n",
        "        nsents += 1\n",
        "        tmp_sent = sent.lower().split(' ')\n",
        "        if '' in tmp_sent:\n",
        "            tmp_sent.remove('')\n",
        "\n",
        "        for w in tmp_sent:\n",
        "            word_counts[w] = word_counts.get(w, 0) + 1\n",
        "\n",
        "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
        "    print ('filtered words from %d to %d' % (len(word_counts), len(vocab)))\n",
        "\n",
        "    ixtoword = {}\n",
        "    ixtoword[0] = '<bos>'\n",
        "    ixtoword[1] = '<eos>'\n",
        "    ixtoword[2] = '<pad>'\n",
        "    ixtoword[3] = '<unk>'\n",
        "\n",
        "    wordtoix = {}\n",
        "    wordtoix['<bos>'] = 0\n",
        "    wordtoix['<eos>'] = 1\n",
        "    wordtoix['<pad>'] = 2\n",
        "    wordtoix['<unk>'] = 3\n",
        "\n",
        "    for idx, w in enumerate(vocab):\n",
        "        wordtoix[w] = idx + 4\n",
        "        ixtoword[idx+4] = w\n",
        "\n",
        "    word_counts['<eos>'] = nsents\n",
        "    word_counts['<bos>'] = nsents\n",
        "    word_counts['<pad>'] = nsents\n",
        "    word_counts['<unk>'] = nsents\n",
        "\n",
        "    bias_init_vector = np.array([1.0 * word_counts[ ixtoword[i] ] for i in ixtoword])\n",
        "    bias_init_vector /= np.sum(bias_init_vector) # normalize to frequencies\n",
        "    bias_init_vector = np.log(bias_init_vector)\n",
        "    bias_init_vector -= np.max(bias_init_vector) # shift to nice numeric range\n",
        "\n",
        "    return wordtoix, ixtoword, bias_init_vector\n",
        "\n",
        "\n",
        "#######################################################################################################\n",
        "# Parameters Setting\n",
        "#######################################################################################################\n",
        "batch_size = 50 # Being support batch_size\n",
        "num_boxes = 50 # number of Detected regions in each image\n",
        "feats_dim = 4096 # feature dimensions of each regions\n",
        "project_dim = 1024 # project the features to one vector, which is 1024 dimensions\n",
        "\n",
        "sentRNN_lstm_dim = 512 # the sentence LSTM hidden units\n",
        "sentRNN_FC_dim = 1024 # the fully connected units\n",
        "wordRNN_lstm_dim = 512 # the word LSTM hidden units\n",
        "word_embed_dim = 1024 # the learned embedding vectors for the words\n",
        "\n",
        "S_max = 6\n",
        "N_max = 30\n",
        "T_stop = 0.5\n",
        "\n",
        "n_epochs = 500\n",
        "learning_rate = 0.0001\n",
        "\n",
        "\n",
        "#######################################################################################################\n",
        "# Word vocubulary and captions preprocessing stage\n",
        "#######################################################################################################\n",
        "img2paragraph = pickle.load(open('/content/drive/My Drive/images2/img2paragraph', 'rb'))\n",
        "all_sentences = []\n",
        "for key, paragraph in img2paragraph.items():\n",
        "    for each_sent in paragraph[1]:\n",
        "        each_sent.replace(',', ' ,')\n",
        "        all_sentences.append(each_sent)\n",
        "        \n",
        "word2idx, idx2word, bias_init_vector = preProBuildWordVocab(all_sentences, word_count_threshold=2)\n",
        "\n",
        "if os.path.exists('/content/drive/My Drive/images2/idx2word_batch.npy') == False:\n",
        "    np.save('/content/drive/My Drive/images2/idx2word_batch', idx2word)\n",
        "\n",
        "img2paragraph_modify = {}\n",
        "for img_name, img_paragraph in img2paragraph.items():\n",
        "    img_paragraph_1 = img_paragraph[1]\n",
        "    \n",
        "    # img_paragraph_1 is a list\n",
        "    # it may contain the element: '' or ' ', like this:\n",
        "    # [[\"a man is walking\"], [\"the dog is running\"], [\"\"], [\" \"]]\n",
        "    # so, we should remove them ' ' and '' element\n",
        "    if '' in img_paragraph_1:\n",
        "        img_paragraph_1.remove('')\n",
        "    if ' ' in paragraph[1]:\n",
        "        img_paragraph_1.remove(' ')\n",
        "\n",
        "    # the number sents in each paragraph\n",
        "    # if the sents is bigger than S_max,\n",
        "    # we force the number of sents to be S_max\n",
        "    img_num_sents = len(img_paragraph_1)\n",
        "    if img_num_sents > S_max:\n",
        "        img_num_sents = S_max\n",
        "\n",
        "    # if a paragraph has 4 sentences\n",
        "    # then the img_num_distribution will be like this:\n",
        "    # [0, 0, 0, 1, 1, 1]\n",
        "    img_num_distribution = np.zeros([S_max], dtype=np.int32)\n",
        "    img_num_distribution[img_num_sents-1:] = 1\n",
        "\n",
        "    # we multiply the number 2, because the <pad> is encoded into 2\n",
        "    img_captions_matrix = np.ones([S_max, N_max+1], dtype=np.int32) * 2 # zeros([6, 50])\n",
        "    for idx, img_sent in enumerate(img_paragraph_1):\n",
        "        # the number of sentences is img_num_sents\n",
        "        if idx == img_num_sents:\n",
        "            break\n",
        "\n",
        "        # because we treat the ',' as a word\n",
        "        img_sent = img_sent.replace(',', ' ,')\n",
        "\n",
        "        # Because I have preprocess the paragraph_v1.json file in VScode before,\n",
        "        # and I delete all the 2, 3, 4...bankspaces\n",
        "        # so, actually, the 'elif' code will never run\n",
        "        if img_sent[0] == ' ' and img_sent[1] != ' ':\n",
        "            img_sent = img_sent[1:]\n",
        "        elif img_sent[0] == ' ' and img_sent[1] == ' ' and img_sent[2] != ' ':\n",
        "            img_sent = img_sent[2:]\n",
        "\n",
        "        # Be careful the last part in a sentence, like this:\n",
        "        # '...world.'\n",
        "        # '...world. '\n",
        "        if img_sent[-1] == '.':\n",
        "            img_sent = img_sent[0:-1]\n",
        "        elif img_sent[-1] == ' ' and img_sent[-2] == '.':\n",
        "            img_sent = img_sent[0:-2]\n",
        "\n",
        "        # Last, we add the <bos> and the <eos> in each sentences\n",
        "        img_sent = '<bos> ' + img_sent + ' <eos>'\n",
        "\n",
        "        # translate each word in a sentence into the unique number in word2idx dict\n",
        "        # when we meet the word which is not in the word2idx dict, we use the mark: <unk>\n",
        "        for idy, word in enumerate(img_sent.lower().split(' ')):\n",
        "            # because the biggest number of words in a sentence is N_max, here is 50\n",
        "            if idy == N_max:\n",
        "                break\n",
        "\n",
        "            if word in word2idx:\n",
        "                img_captions_matrix[idx, idy] = word2idx[word]\n",
        "            else:\n",
        "                img_captions_matrix[idx, idy] = word2idx['<unk>']\n",
        "\n",
        "    # this is a matrix of number\n",
        "    # Pay attention, the value type 'img_name' here is NUMBER, I change it to STRING type\n",
        "    img2paragraph_modify[str(img_name)] = [img_num_distribution, img_captions_matrix]\n",
        "    if os.path.exists('/content/drive/My Drive/images2/img2paragraph_modify_batch') == False:    \n",
        "      with open('/content/drive/My Drive/images2/img2paragraph_modify_batch', 'wb') as f:\n",
        "          pickle.dump(img2paragraph_modify, f)\n",
        "\n",
        "#print(\"img2paragraph_modify \",img2paragraph_modify[\"2356347\"][1])\n",
        "print (\"finish word vocubulary and captions preprocessing stage\")\n",
        "\n",
        "#######################################################################################################\n",
        "# Train, validation and testing stage\n",
        "#######################################################################################################\n",
        "def train():\n",
        "  # Model Initialization:\n",
        "    model_path = '/content/drive/My Drive/images2/models_batch/'\n",
        "    train_feats_path = '/content/drive/My Drive/images2/im2p_train_output.h5'\n",
        "    train_output_file = h5py.File(train_feats_path, 'r')\n",
        "    train_feats = train_output_file.get('feats')\n",
        "    train_imgs_full_path_lists = open('/content/drive/My Drive/images2/imgs_train_path.txt').read().splitlines()\n",
        "    train_imgs_names = list(map(lambda x: os.path.basename(x).split('.')[0], train_imgs_full_path_lists))\n",
        "\n",
        "    # n_words, batch_size, num_boxes, feats_dim, project_dim, sentRNN_lstm_dim, sentRNN_FC_dim, wordRNN_lstm_dim, S_max, N_max\n",
        "    model = RegionPooling_HierarchicalRNN(n_words = len(word2idx),\n",
        "                                          batch_size = batch_size,\n",
        "                                          num_boxes = num_boxes,\n",
        "                                          feats_dim = feats_dim,\n",
        "                                          project_dim = project_dim,\n",
        "                                          sentRNN_lstm_dim = sentRNN_lstm_dim,\n",
        "                                          sentRNN_FC_dim = sentRNN_FC_dim,\n",
        "                                          wordRNN_lstm_dim = wordRNN_lstm_dim,\n",
        "                                          S_max = S_max,\n",
        "                                          N_max = N_max,\n",
        "                                          word_embed_dim = word_embed_dim,\n",
        "                                          bias_init_vector = bias_init_vector)\n",
        "\n",
        "    tf_feats, tf_num_distribution, tf_captions_matrix, tf_captions_masks, tf_loss, tf_loss_sent, tf_loss_word = model.build_model()\n",
        "    #print(tf_captions_masks)\n",
        "    #print(tf_captions_masks.type)\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "\n",
        "      saver = tf.compat.v1.train.Saver(max_to_keep=500, write_version=1)\n",
        "      train_op = tf.compat.v1.train.GradientDescentOptimizer(learning_rate).minimize(tf_loss)\n",
        "      tf.compat.v1.global_variables_initializer().run()\n",
        "\n",
        "      # when you want to train the model from the front model\n",
        "      new_saver = tf.compat.v1.train.Saver()\n",
        "      #new_saver = tf.compat.v1.train.import_meta_graph('/content/drive/My Drive/decoder/model_batch/model-92.meta')\n",
        "      #ew_saver.save(sess,'/content/drive/My Drive/decoder/model_batch/model-92.meta')\n",
        "      #new_saver.restore(sess, tf.train.latest_checkpoint('/content/drive/My Drive/decoder/model_batch/./'))\n",
        "\n",
        "      all_vars = tf.compat.v1.trainable_variables()\n",
        "\n",
        "      # open a loss file to record the loss value\n",
        "      loss_fd = open('/content/drive/My Drive/images2/loss_batch.txt', 'w')\n",
        "      img2idx = {}\n",
        "      for idx, img in enumerate(train_imgs_names):\n",
        "          img2idx[img] = idx\n",
        "\n",
        "      # plt draw the loss curve\n",
        "      # refer from: http://stackoverflow.com/questions/11874767/real-time-plotting-in-while-loop-with-matplotlib\n",
        "      loss_to_draw = []\n",
        "\n",
        "      for epoch in range(0, n_epochs):\n",
        "          loss_to_draw_epoch = []\n",
        "          # disorganize the order\n",
        "          random.shuffle(train_imgs_names)\n",
        "\n",
        "          for start, end in zip(range(0, len(train_imgs_names), batch_size),\n",
        "                                range(batch_size, len(train_imgs_names), batch_size)):\n",
        "\n",
        "              start_time = time.time()\n",
        "\n",
        "              img_name = train_imgs_names[start:end]\n",
        "              current_feats_index = (map(lambda x: img2idx[x], img_name))\n",
        "              current_feats = np.asarray( (map(lambda x: train_feats[x], current_feats_index)) )\n",
        "              \n",
        "              #print(current_feats.shape)\n",
        "\n",
        "              current_num_distribution = np.asarray(list(map(lambda x: img2paragraph_modify[x][0], img_name) ))\n",
        "              current_captions_matrix =  np.asarray(list(map(lambda x: img2paragraph_modify[x][1], img_name) ))\n",
        "\n",
        "              current_captions_masks = np.zeros((current_captions_matrix.shape[0], current_captions_matrix.shape[1], current_captions_matrix.shape[2]))\n",
        "              # find the non-zero element\n",
        "              nonzeros = np.array( list(map(lambda each_matrix: np.array( list(map(lambda x: (x != 2).sum() + 1, each_matrix )) ), current_captions_matrix )) )\n",
        "              #print(current_captions_masks)\n",
        "              for i in range(batch_size):\n",
        "                  for ind, row in enumerate(current_captions_masks[i]):\n",
        "                      row[:(nonzeros[i, ind]-1)] = 1\n",
        "\n",
        "              # shape of current_feats: batch_size x 50 x 4096\n",
        "              # shape of current_num_distribution: batch_size x 6\n",
        "              # shape of current_captions_matrix: batch_size x 6 x 50\n",
        "              #print(current_captions_masks)\n",
        "              _, loss_val, loss_sent, loss_word= sess.run(\n",
        "                                  [train_op, tf_loss, tf_loss_sent, tf_loss_word],\n",
        "                                  feed_dict={\n",
        "                                            tf_feats: current_feats,\n",
        "                                            tf_num_distribution: current_num_distribution,\n",
        "                                            tf_captions_matrix: current_captions_matrix,\n",
        "                                            tf_captions_masks: current_captions_masks\n",
        "                                  })\n",
        "\n",
        "              # append loss to list in a epoch\n",
        "              loss_to_draw_epoch.append(loss_val)\n",
        "\n",
        "              # running information\n",
        "              print ('idx: ', start, ' Epoch: ', epoch, ' loss: ', loss_val, ' loss_sent: ', loss_sent, ' loss_word: ', loss_word, ' Time cost: ', str((time.time() - start_time)))\n",
        "              loss_fd.write('epoch ' + str(epoch) + ' loss ' + str(loss_val))\n",
        "\n",
        "          # draw loss curve every epoch\n",
        "          loss_to_draw.append(np.mean(loss_to_draw_epoch))\n",
        "          plt_save_dir = '/content/drive/My Drive/images2/loss_imgs'\n",
        "          plt_save_img_name = str(epoch) + '.png'\n",
        "          plt.plot(range(len(loss_to_draw)), loss_to_draw, color='g')\n",
        "          plt.grid(True)\n",
        "          plt.savefig(os.path.join(plt_save_dir, plt_save_img_name))\n",
        "\n",
        "          if np.mod(epoch, 10) == 0:\n",
        "              print (\"Epoch \", epoch, \" is done. Saving the model ...\")\n",
        "              saver.save(sess, os.path.join(model_path, 'model'), global_step=epoch)\n",
        "      loss_fd.close()\n",
        "\n",
        "\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}