{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DemoEncoder",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahomudgamalfcis/Image-Paragraph-Captioning/blob/master/DemoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgBSrgQhCNFH",
        "colab_type": "text"
      },
      "source": [
        "#1- Change Version of CUDA from 10.0 to 9.2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlaElJoKltGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for Current version\n",
        "!nvcc --version\n",
        "#--------------------------------------------------\n",
        "\n",
        "# Uninstall the current version of CUDA\n",
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update\n",
        "#---------------------------------------------------\n",
        "\n",
        "# Install the new version of CUDA\n",
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9-2\n",
        "#---------------------------------------------------\n",
        "\n",
        "# check if CUDA 9.2 is installed\n",
        "!nvcc --version\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOLZMdF4DSsa",
        "colab_type": "text"
      },
      "source": [
        "#2- Setup Torch and It's Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ONhlFJ1l7ws1",
        "colab": {}
      },
      "source": [
        "# This Commands will install Torch with luaJIT\n",
        "!git clone https://github.com/nagadomi/distro.git ~/torch --recursive\n",
        "%cd ~/torch\n",
        "!bash install-deps\n",
        "!./install.sh\n",
        "#--------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyi0EfY8ZAgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this will install torch-rnn packcage\n",
        "!/root/torch/install/bin/luarocks  install https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/torch-rnn-scm-1.rockspec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I-VeSJIZLDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' this command is to install stnbhw-scm-1, but it is a modified repo. we modified the CMakeLists file to change GPU architecture to \n",
        "fit the one which installed in Googel Colab. the line we changed is \n",
        " IF (CUDA_FOUND)\n",
        "   LIST(APPEND CUDA_NVCC_FLAGS \"-arch=sm_20\") To \n",
        "\n",
        " IF (CUDA_FOUND)\n",
        "   LIST(APPEND CUDA_NVCC_FLAGS \"-arch=sm_30\")'''\n",
        "!/root/torch/install/bin/luarocks install https://raw.githubusercontent.com/mahomudgamalfcis/stnbhwd/master/stnbhwd-scm-1.rockspec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6twl7vaRZPgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the commands below will install HDF5-1.10 \n",
        "%cd /content\n",
        "!git clone https://github.com/anibali/torch-hdf5.git\n",
        "%cd torch-hdf5\n",
        "!git checkout hdf5-1.10 \n",
        "!/root/torch/install/bin/luarocks make hdf5-0-0.rockspec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHsaSm4-Za21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this command to display Installed packages by Luarocks\n",
        "!/root/torch/install/bin/luarocks list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BknEZrgG-ly",
        "colab_type": "text"
      },
      "source": [
        "#3- Clone im2p repository "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6QiG0OCT_Wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/mahomudgamalfcis/im2p.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HocfnFjJMx9b",
        "colab_type": "text"
      },
      "source": [
        "### i- Download pre-trained model of Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlP4sAsxb4ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/im2p\n",
        "!mkdir -p data/models/densecap\n",
        "%cd ./data/models/densecap\n",
        "!wget http://cs.stanford.edu/people/jcjohns/densecap/densecap-pretrained-vgg16.t7.zip\n",
        "!unzip densecap-pretrained-vgg16.t7.zip\n",
        "!rm densecap-pretrained-vgg16.t7.zip\n",
        "%cd ../../../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edThAFCFnKzV",
        "colab_type": "text"
      },
      "source": [
        "###ii-Attach Dataset from Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIhmmII6ngDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount The place where our dataset exist..\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHWY9xhMNYSi",
        "colab_type": "text"
      },
      "source": [
        "###iii- Extract feature for Training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kF_jbqEYdBjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read train_split file which contains all ids of training images\n",
        "train_imgs_ID = \"/content/im2p/data/train_split.json\"\n",
        "with open(train_imgs_ID,'r') as all_train_imgs:\n",
        "    trainImageID = json.load(all_train_imgs)\n",
        "print(len(trainImageID))\n",
        "#-----------------------------------------\n",
        "\n",
        "# pick all training Images from all images\n",
        "train_images_path = \"/content/drive/My Drive/VG/Images\"\n",
        "train_images = glob.glob(train_images_path + \"/*.jpg\")\n",
        "f = open(\"imgs_train_path.txt\", \"w\")\n",
        "for img in train_images:\n",
        "  img_name = int(os.path.basename(img).split(\".\")[0])\n",
        "  if img_name in trainImageID:\n",
        "      f.write(img + \"\\n\")\n",
        "f.close()\n",
        "# At this step we couldn't extrat the features of all training images in one step\n",
        "# so we divide it into 8 files each file contain set of images. but the previous code \n",
        "# read all images and save it in one text file. \n",
        "\n",
        "%cd /content/im2p\n",
        "!/root/torch/install/bin/th /content/im2p/extract_features.lua -boxes_per_image 50 -max_images -1 -checkpoint /content/im2p/data/models/densecap/densecap-pretrained-vgg16.t7  -input_txt /content/im2p/imgs_train_path.txt \\\n",
        "                          -output_h5 ./data/im2p_train_output.h5 -gpu 0 -use_cudnn 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKuBDkOvN0WH",
        "colab_type": "text"
      },
      "source": [
        "###vi- Extract feature for Testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyVFAHdZODHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read train_split file which contains all ids of training images\n",
        "train_imgs_ID = \"/content/im2p/data/test_split.json\"\n",
        "with open(train_imgs_ID,'r') as all_train_imgs:\n",
        "    testImageID = json.load(all_train_imgs)\n",
        "print(len(testImageID))\n",
        "#-----------------------------------------\n",
        "\n",
        "# pick all training Images from all images\n",
        "train_images_path = \"/content/drive/My Drive/VG/Images\"\n",
        "train_images = glob.glob(train_images_path + \"/*.jpg\")\n",
        "f = open(\"imgs_train_path.txt\", \"w\")\n",
        "for img in train_images:\n",
        "  img_name = int(os.path.basename(img).split(\".\")[0])\n",
        "  if img_name in testImageID:\n",
        "      f.write(img + \"\\n\")\n",
        "f.close()\n",
        "%cd /content/im2p\n",
        "!/root/torch/install/bin/th /content/im2p/extract_features.lua -boxes_per_image 50 -max_images -1 -checkpoint /content/im2p/data/models/densecap/densecap-pretrained-vgg16.t7  -input_txt /content/im2p/imgs_test_path.txt \\\n",
        "                          -output_h5 ./data/im2p_test_output.h5 -gpu 0 -use_cudnn 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMzjIMooOqiV",
        "colab_type": "text"
      },
      "source": [
        "#4- Check the Output of Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6CgN11FfxMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "f = h5py.File(r'/content/drive/My Drive/VG/im2p_test_output.h5')\n",
        "list(f)\n",
        "f['feats'].shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}